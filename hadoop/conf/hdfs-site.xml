<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->

<!-- Put site-specific property overrides in this file. -->

<configuration>
    <property>
        <name>dfs.replication</name>
        <value>DFS_REPLICATION</value>
        <description>HDFS is partly designed to allow storage failures and uses
            replication for this. Since either your data on myhadoop jobs is only 
            supposed to live through a single run or you can use persistent data
            that will most likely run on solid hardware it is quite save to keep
            replication at 1 and reduce the IO overhead.
        </description>
    </property>

    <property>
        <name>dfs.name.dir</name>
        <value>DFS_NAME_DIR</value>
        <description>Determines where on the local filesystem the DFS name node
            should store the name table.  If this is a comma-delimited list
            of directories then the name table is replicated in all of the
            directories, for redundancy. </description>
        <final>true</final>
    </property>

    <property>
        <name>dfs.data.dir</name>
        <value>DFS_DATA_DIR</value>
        <description>Determines where on the local filesystem an DFS data node
            should store its blocks.  If this is a comma-delimited
            list of directories, then data will be stored in all named
            directories, typically on different devices.
            Directories that do not exist are ignored.
        </description>
        <final>true</final>
    </property>

    <property>
        <name>dfs.block.size</name>
        <value></value>
        <description>The HDFS block size defines the size of the parts in which 
            the HDFS files will be divided and distributed over the data nodes.
        </description>
    </property>

</configuration>
